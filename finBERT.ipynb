{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dataset/can_statements.csv', index_col=0)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bank canada today increased target overnight rate bank rate deposit rate bank also continuing policy quantitative tightening global canadian economies evolving broadly line bank july projection effects covid-19 outbreaks ongoing supply disruptions war ukraine continue dampen growth boost prices global inflation remains high measures core inflation moving countries response central banks around world continue tighten monetary policy economic activity united states moderated although us labour mar'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tokens = [t for t in word_tokenize(df.text[0]) if t not in stopwords] \n",
    "def tokenize(text):\n",
    "    tok = [t for t in word_tokenize(text) if t not in stopwords and not t.isnumeric()]\n",
    "    sentence = ''\n",
    "    for word in tok:\n",
    "        word = word if len(word) > 1 else ''\n",
    "        word = '' if word.isnumeric() else word\n",
    "        word = word.lower()\n",
    "        \n",
    "        if word != '':\n",
    "            sentence += word + ' '\n",
    "    return sentence[:500]\n",
    "\n",
    "df['text'] = df['text'].apply(tokenize)\n",
    "df.iloc[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import scipy.special\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def sentiment(input):\n",
    "    inputs = tokenizer(input, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    scores = {k: v for k, v in zip(model.config.id2label.values(), scipy.special.softmax(logits.numpy().squeeze()))}\n",
    "    return scores['positive'] - scores['negative']\n",
    "# {'negative': 0.034473564, 'neutral': 0.067165166, 'positive': 0.8983614}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['text'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/dataset/can_statements_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8cb0f8b00c91089d7d68f2ff6cf4f0b3fda5f63788f7f24d80ab4337f0c588a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
